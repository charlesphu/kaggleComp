{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:18<00:00, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new annotations file to: augmented/annotations.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Paired Rotation Class ---\n",
    "class RandomRotatePair:\n",
    "    def __init__(self, degrees):\n",
    "        self.degrees = degrees\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        angle = random.uniform(-self.degrees, self.degrees)\n",
    "        image = TF.rotate(image, angle)\n",
    "        mask = TF.rotate(mask, angle, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        return image, mask\n",
    "\n",
    "# --- Dataset-like class ---\n",
    "class SemiSegmentationExporter:\n",
    "    def __init__(self, images_dir, masks_dir, annotation_path, transform=None, mask_transform=None):\n",
    "        with open(annotation_path, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def export(self, save_dir_images, save_dir_masks, max_samples=None):\n",
    "        os.makedirs(save_dir_images, exist_ok=True)\n",
    "        os.makedirs(save_dir_masks, exist_ok=True)\n",
    "\n",
    "        samples = self.annotations if max_samples is None else self.annotations[:max_samples]\n",
    "\n",
    "        new_annotations = []\n",
    "\n",
    "        for idx, ann in tqdm(enumerate(samples), total=len(samples)):\n",
    "            img_name = ann['image']\n",
    "            mask_name = ann['mask']\n",
    "            class_id = ann.get('class_id', None)  # keep class_id if present\n",
    "\n",
    "            img_path = os.path.join(self.images_dir, img_name)\n",
    "            mask_path = os.path.join(self.masks_dir, mask_name)\n",
    "\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            mask = Image.open(mask_path)\n",
    "\n",
    "            # Apply augmentation\n",
    "            image, mask = RandomRotatePair(360)(image, mask)\n",
    "\n",
    "            if self.transform:\n",
    "                image_t = self.transform(image)\n",
    "            else:\n",
    "                image_t = image\n",
    "\n",
    "            if self.mask_transform:\n",
    "                mask_t = self.mask_transform(mask)\n",
    "                if mask_t.dim() == 3 and mask_t.shape[0] == 1:\n",
    "                    mask_t = mask_t.squeeze(0)\n",
    "                mask_t = mask_t.long()\n",
    "            else:\n",
    "                mask_t = torch.from_numpy(np.array(mask, dtype=np.int64))\n",
    "\n",
    "            # Save augmented image and mask\n",
    "            aug_img_name = f\"aug_{idx:04d}.png\"\n",
    "            aug_mask_name = f\"aug_{idx:04d}.png\"\n",
    "\n",
    "            save_img_path = os.path.join(save_dir_images, aug_img_name)\n",
    "            save_mask_path = os.path.join(save_dir_masks, aug_mask_name)\n",
    "\n",
    "            # Convert tensor back to PIL Image for saving if needed\n",
    "            if isinstance(image_t, torch.Tensor):\n",
    "                save_img = transforms.ToPILImage()(image_t)\n",
    "            else:\n",
    "                save_img = image_t\n",
    "\n",
    "            if isinstance(mask_t, torch.Tensor):\n",
    "                save_mask = Image.fromarray(mask_t.cpu().numpy().astype(np.uint8))\n",
    "            else:\n",
    "                save_mask = mask_t\n",
    "\n",
    "            save_img.save(save_img_path)\n",
    "            save_mask.save(save_mask_path)\n",
    "\n",
    "            # Append new annotation entry\n",
    "            new_ann = {\n",
    "                'image': aug_img_name,\n",
    "                'mask': aug_mask_name,\n",
    "            }\n",
    "            if class_id is not None:\n",
    "                new_ann['class_id'] = class_id\n",
    "            new_annotations.append(new_ann)\n",
    "\n",
    "        # Save the new annotations JSON file\n",
    "        new_ann_path = os.path.join(os.path.dirname(save_dir_images), 'annotations.json')\n",
    "        with open(new_ann_path, 'w') as f:\n",
    "            json.dump(new_annotations, f, indent=2)\n",
    "        print(f\"Saved new annotations file to: {new_ann_path}\")\n",
    "\n",
    "\n",
    "# --- Transform setup ---\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=Image.NEAREST),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Lambda(lambda x: x[0] if x.shape[0] == 1 else x.max(dim=0)[0]),\n",
    "])\n",
    "\n",
    "exporter = SemiSegmentationExporter(\n",
    "    images_dir='train-semi',\n",
    "    masks_dir='train-semi-segmentation',\n",
    "    annotation_path='train_semi_annotations_with_seg_ids.json',\n",
    "    transform=image_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "\n",
    "exporter.export(\n",
    "    save_dir_images='augmented/train-semi',\n",
    "    save_dir_masks='augmented/train-semi-segmentation',\n",
    "    max_samples=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
