{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be07ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "# from google.colab import drive\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d795ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemiSupervisedDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, label_json, transform=None, mask_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "        with open(label_json, 'r') as f:\n",
    "            self.labels = json.load(f)\n",
    "\n",
    "        self.image_files = [entry[\"image\"] for entry in self.labels]\n",
    "        self.label_dict = {entry[\"image\"]: entry[\"class_id\"] for entry in self.labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        basename, _ = os.path.splitext(image_name)\n",
    "        mask_path = os.path.join(self.mask_dir, basename + '.png')\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        label = self.label_dict[image_name]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomRotation(degrees=5), \n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.Resize((224, 224)),  # Resize to ResNet-18 input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=Image.NEAREST),\n",
    "    transforms.PILToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378121ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 2)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        layers = [BasicBlock(self.in_channels, out_channels, stride, downsample)]\n",
    "        self.in_channels = out_channels\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192d2e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18(num_classes=50)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b83eb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset = SemiSupervisedDataset(\n",
    "    image_dir=\"train-semi\",\n",
    "    mask_dir=\"train-semi-segmentation\",\n",
    "    label_json=\"train_semi_annotations_with_seg_ids.json\",\n",
    "    transform=image_transform,\n",
    "    mask_transform=mask_transform\n",
    ")\n",
    "\n",
    "labeled_loader = DataLoader(labeled_dataset, batch_size=8, shuffle=True, num_workers=1)\n",
    "\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image  # Just return image\n",
    "\n",
    "    \n",
    "unlabeled_dataset = UnlabeledDataset(\n",
    "    image_dir=\"train-unlabeled\",  # <- use your unlabeled data path\n",
    "    transform=image_transform,\n",
    ")\n",
    "\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=8, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b09590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Self-training Round 1 ===\n",
      "Supervised Epoch 1/4, Accuracy: 1.40%\n",
      "Supervised Epoch 2/4, Accuracy: 3.40%\n",
      "Supervised Epoch 3/4, Accuracy: 3.60%\n",
      "Supervised Epoch 4/4, Accuracy: 4.20%\n",
      "Added 133 pseudo-labeled examples.\n",
      "Semi-Supervised Epoch 1/3, Accuracy: 22.59%\n",
      "Semi-Supervised Epoch 2/3, Accuracy: 24.01%\n",
      "Semi-Supervised Epoch 3/3, Accuracy: 23.85%\n",
      "\n",
      "=== Self-training Round 2 ===\n",
      "Supervised Epoch 1/4, Accuracy: 5.00%\n",
      "Supervised Epoch 2/4, Accuracy: 8.60%\n",
      "Supervised Epoch 3/4, Accuracy: 9.40%\n",
      "Supervised Epoch 4/4, Accuracy: 8.00%\n",
      "Added 13 pseudo-labeled examples.\n",
      "Semi-Supervised Epoch 1/3, Accuracy: 7.41%\n",
      "Semi-Supervised Epoch 2/3, Accuracy: 11.70%\n",
      "Semi-Supervised Epoch 3/3, Accuracy: 11.31%\n",
      "\n",
      "=== Self-training Round 3 ===\n",
      "Supervised Epoch 1/4, Accuracy: 9.40%\n",
      "Supervised Epoch 2/4, Accuracy: 12.40%\n",
      "Supervised Epoch 3/4, Accuracy: 11.80%\n",
      "Supervised Epoch 4/4, Accuracy: 14.00%\n",
      "Added 48 pseudo-labeled examples.\n",
      "Semi-Supervised Epoch 1/3, Accuracy: 17.15%\n",
      "Semi-Supervised Epoch 2/3, Accuracy: 19.34%\n",
      "Semi-Supervised Epoch 3/3, Accuracy: 18.80%\n",
      "\n",
      "=== Self-training Round 4 ===\n",
      "Supervised Epoch 1/4, Accuracy: 16.00%\n",
      "Supervised Epoch 2/4, Accuracy: 16.60%\n",
      "Supervised Epoch 3/4, Accuracy: 19.80%\n",
      "Supervised Epoch 4/4, Accuracy: 20.00%\n",
      "Added 7 pseudo-labeled examples.\n",
      "Semi-Supervised Epoch 1/3, Accuracy: 18.34%\n",
      "Semi-Supervised Epoch 2/3, Accuracy: 18.93%\n",
      "Semi-Supervised Epoch 3/3, Accuracy: 22.09%\n",
      "\n",
      "=== Self-training Round 5 ===\n",
      "Supervised Epoch 1/4, Accuracy: 23.40%\n",
      "Supervised Epoch 2/4, Accuracy: 26.40%\n",
      "Supervised Epoch 3/4, Accuracy: 24.00%\n",
      "Supervised Epoch 4/4, Accuracy: 30.00%\n",
      "Added 25 pseudo-labeled examples.\n",
      "Semi-Supervised Epoch 1/3, Accuracy: 32.38%\n",
      "Semi-Supervised Epoch 2/3, Accuracy: 32.76%\n",
      "Semi-Supervised Epoch 3/3, Accuracy: 35.43%\n",
      "\n",
      "=== Self-training Complete ===\n"
     ]
    }
   ],
   "source": [
    "num_self_training_rounds = 10\n",
    "supervised_epochs = 4\n",
    "semi_supervised_epochs = 3\n",
    "pseudo_conf_threshold = 0.85\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for self_training_round in range(num_self_training_rounds):\n",
    "    print(f\"\\n=== Self-training Round {self_training_round + 1} ===\")\n",
    "\n",
    "    # --- Step 1: Supervised training on labeled data ---\n",
    "    model.train()\n",
    "    for epoch in range(supervised_epochs):\n",
    "        correct = total = 0\n",
    "        for images, labels in labeled_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc = 100 * correct / total\n",
    "        print(f\"Supervised Epoch {epoch+1}/{supervised_epochs}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    # --- Step 2: Generate pseudo-labels on unlabeled data ---\n",
    "    model.eval()\n",
    "    pseudo_labeled_data = []  # FIXED: Clear previous pseudo-labels each round\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in unlabeled_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            confidence, predicted = torch.max(probs, dim=1)\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                if confidence[i] >= pseudo_conf_threshold:\n",
    "                    # FIXED: Store as tuple of (tensor, label) without extra processing\n",
    "                    pseudo_labeled_data.append((images[i].cpu().clone(), predicted[i].cpu()))\n",
    "\n",
    "    print(f\"Added {len(pseudo_labeled_data)} pseudo-labeled examples.\")\n",
    "    \n",
    "    # Skip if no pseudo-labels generated\n",
    "    if len(pseudo_labeled_data) == 0:\n",
    "        print(\"No pseudo-labels generated, continuing to next round...\")\n",
    "        continue\n",
    "\n",
    "    # --- Step 3: Create pseudo-labeled dataset and combine ---\n",
    "    class PseudoLabelDataset(Dataset):\n",
    "        def __init__(self, pseudo_data):\n",
    "            self.data = pseudo_data\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image, label = self.data[idx]\n",
    "            return image, label  # FIXED: Return tensors directly, no transform issues\n",
    "\n",
    "    pseudo_dataset = PseudoLabelDataset(pseudo_labeled_data)\n",
    "    combined_dataset = ConcatDataset([labeled_dataset, pseudo_dataset])\n",
    "    combined_loader = DataLoader(combined_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "    # --- Step 4: Train on combined labeled + pseudo-labeled data ---\n",
    "    model.train()\n",
    "    for epoch in range(semi_supervised_epochs):\n",
    "        correct = total = 0\n",
    "        for images, labels in combined_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        acc = 100 * correct / total\n",
    "        print(f\"Semi-Supervised Epoch {epoch+1}/{semi_supervised_epochs}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    # Increase confidence threshold\n",
    "    if len(pseudo_labeled_data) < 20:\n",
    "        pseudo_conf_threshold -= 0.02\n",
    "    else:\n",
    "        pseudo_conf_threshold = max(0.95, pseudo_conf_threshold + 0.02)\n",
    "\n",
    "print(\"\\n=== Self-training Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to: saved_models/resnet18v5.pth\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def save_model_with_timestamp(model, save_dir=\"models\", model_name=\"my_model\"):\n",
    "    \"\"\"\n",
    "    Saves a PyTorch model to a specified directory with a timestamp in its filename.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The PyTorch model to save.\n",
    "        save_dir (str): The directory where the model should be saved.\n",
    "                        Defaults to \"models\".\n",
    "        model_name (str): The base name for the model file.\n",
    "                          Defaults to \"my_model\".\n",
    "    \"\"\"\n",
    "    # 1. Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 2. Generate a timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # Format: YYYYMMDD_HHMMSS\n",
    "\n",
    "    # 3. Create the full filename with path\n",
    "    filename = f\"{model_name}.pth\" # Using .pth or .pt extension\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "    # 4. Save the model\n",
    "    torch.save(model, filepath)\n",
    "    print(f\"Model saved successfully to: {filepath}\")\n",
    "\n",
    "save_model_with_timestamp(model, save_dir=\"saved_models\", model_name=\"resnet18v6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
